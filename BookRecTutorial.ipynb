{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-F6HoE9Yjdnl"
      },
      "source": [
        "# 图书推荐教程\n",
        "### 数据悦读大赛作品\n",
        "这个笔记本展示了如何对原始数据集进行预处理、特征提取、模型训练、评估等，最终将生成的数据传送至远端服务器上进行推荐。笔记本中可能需要修改的是原始数据的存放路径，即文件中的DataDir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U_YPAK5Ujdnp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ProjectFolderDir = 'D:/OneDrive - MSFT/CodeSpace/BookRecSystem/'   # 项目文件夹的路径是相对于本笔记本路径而言的，当然也可以使用绝对路径\n",
        "DataDir = 'D:/OneDrive - MSFT/CodeSpace/BookRecSystem/data/raw/' # 原始数据路径，根据实际情况修改"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rdsSxmcjdnq"
      },
      "source": [
        "初步分析阶段先将字段以字符串形式录入，便于后期统一格式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TLh-XcUJjdnr"
      },
      "outputs": [],
      "source": [
        "BigData = pd.read_csv(DataDir + \"浙江大学-图书外借数据-2013~2018.csv\", encoding='utf8', dtype=str)      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wU1YolFejdns"
      },
      "outputs": [],
      "source": [
        "SmallData = pd.read_csv(DataDir + \"浙江大学-图书外借数据-2019.csv\", encoding='utf8', dtype=str)         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpgm-qUQjdnt"
      },
      "source": [
        "下面是构建模型所需要的数据列"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xJzZpvmLjdnt"
      },
      "outputs": [],
      "source": [
        "user_columns = ['PATRON_ID', 'STUDENT_GRADE', 'PATRON_DEPT', 'PATRON_TYPE']\n",
        "# 用户侧特征       用户id          年级            学生学院       学生类型\n",
        "item_columns = ['ITEM_ID', 'SUBLIBRARY', 'ITEM_CALLNO', 'PUBLISH_YEAR', 'AUTHOR', 'TITLE', 'PRESS']\n",
        "# 物品侧特征       记录号      馆藏地         图书索书号        出版年          作者       题目    出版社\n",
        "time = 'LOAN_DATE'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY1n867jjdnu"
      },
      "source": [
        "将两份数据集合并"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_EfMIkpDjdnu"
      },
      "outputs": [],
      "source": [
        "UsedColumns = user_columns + item_columns + [time]\n",
        "UsedData = pd.concat([BigData[UsedColumns], SmallData[UsedColumns]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHEduvnwjdnv"
      },
      "source": [
        "本项目将借阅记录中的空值字段采用相同值’na'进行填充，特征处理时将其作为空特征。对于图书类别，将其索书号按/分割后得到图书大类CALLNO1与小类CALLNO2，将借阅日期转为整形，便于之后比较大小。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AtPc6Mv2jdnv"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_Bletter(str0):   # 取出大写字母\n",
        "    b = re.sub(u\"([^\\u0041-\\u007a])\", \"\", str0)\n",
        "    return b\n",
        "\n",
        "UsedData = UsedData.fillna(value='na')\n",
        "UsedData['CALLNO1'] = UsedData['ITEM_CALLNO'].str.split('/', expand=True)[0].map(lambda x: get_Bletter(str(x)))\n",
        "UsedData['CALLNO2'] = UsedData['ITEM_CALLNO'].str.split('/', expand=True)[1].map(lambda x: get_Bletter(str(x)))\n",
        "UsedData[time]=UsedData[time].astype(int)\n",
        "UsedData = UsedData.drop(columns='ITEM_CALLNO')  # 删掉不再需要的列"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXXIdeYPjdnv"
      },
      "source": [
        "此时可以看到UsedData中的空值消失，并且多出了两个类别列"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGtRpGvyjdnw",
        "outputId": "ba730091-a207-415f-d749-c76eb7f1b4b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2260649 entries, 0 to 192700\n",
            "Data columns (total 13 columns):\n",
            " #   Column         Dtype \n",
            "---  ------         ----- \n",
            " 0   PATRON_ID      object\n",
            " 1   STUDENT_GRADE  object\n",
            " 2   PATRON_DEPT    object\n",
            " 3   PATRON_TYPE    object\n",
            " 4   ITEM_ID        object\n",
            " 5   SUBLIBRARY     object\n",
            " 6   PUBLISH_YEAR   object\n",
            " 7   AUTHOR         object\n",
            " 8   TITLE          object\n",
            " 9   PRESS          object\n",
            " 10  LOAN_DATE      int32 \n",
            " 11  CALLNO1        object\n",
            " 12  CALLNO2        object\n",
            "dtypes: int32(1), object(12)\n",
            "memory usage: 232.8+ MB\n"
          ]
        }
      ],
      "source": [
        "UsedData.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMoaCMmyjdnw"
      },
      "source": [
        "将数据存入./data/processed中，作为后续分析数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c-GURml7jdnw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "if not os.path.exists(ProjectFolderDir+\"data/processed/\"):\n",
        "    os.makedirs(ProjectFolderDir+\"data/processed/\") \n",
        "\n",
        "UsedData.to_csv(ProjectFolderDir+\"data/processed/ZJULibrary2013_2019.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FnWxKoEkRPXZ"
      },
      "outputs": [],
      "source": [
        "del BigData # 将之前的大数据变量清空，空出一部分内存\n",
        "del SmallData\n",
        "del UsedData"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "y4GK7PA-4JvE"
      },
      "source": [
        "#### 若已将两个数据集合并可以直接从此处开始\n",
        "调用代码库中的主函数进行模型训练、评估等操作"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RqzHKeH54If7"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "sys.path.append(ProjectFolderDir)\n",
        "\n",
        "from scripts.MainFile import main\n",
        "\n",
        "# 创建缓存目录\n",
        "\n",
        "if not os.path.exists(ProjectFolderDir+\"temp/\"):\n",
        "    os.makedirs(ProjectFolderDir+\"temp/\")\n",
        "if not os.path.exists(ProjectFolderDir+\"log/\"):\n",
        "    os.makedirs(ProjectFolderDir+\"log/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yq7jM8rG62i"
      },
      "source": [
        "调用主函数即可，运行的日志文件保存在ProjectFolderDir/log目录下"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "moinQ8105-oQ",
        "outputId": "305bd416-826e-4de4-e2ea-ff93fd595f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start: 2023-03-10 10:00:49\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "generate train set, validation set and test set:: 100%|██████████| 44696/44696 [00:10<00:00, 4438.66it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_train: 2794057, n_val: 698515, n_test: 388064\n",
            "12861 cold start user droped \n",
            "train set, validation set and test set have saved in data/processed/data_process.npy\n",
            "standard data has been generated\n",
            "epoch: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "train: 100%|██████████| 1365/1365 [02:48<00:00,  8.08it/s, loss=0.445]\n",
            "calculate auc on train data: 100%|██████████| 1365/1365 [00:27<00:00, 50.20it/s]\n",
            "calculate auc on validation data: 100%|██████████| 342/342 [00:10<00:00, 31.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "auc on train data: 0.829326938875453\n",
            "auc on validation data: 0.8268689704523556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "calculate confusion matrix on test data: 100%|██████████| 190/190 [00:08<00:00, 22.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "confusion_matrix on test data: {'tn': 0.6917209532448256, 'fp': 0.05737197987960749, 'fn': 0.15030252741815783, 'tp': 0.10060453945740909}\n",
            "auc: 0.7923, recall: 0.4010, precision: 0.6368\n",
            "generated user embedding and item embedding\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "user inference: 100%|██████████| 16/16 [00:05<00:00,  2.74it/s]\n",
            "item inference: 100%|██████████| 220/220 [00:06<00:00, 33.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'HR': 0.04692948013193027, 'n_hit': 1494, 'n_total': 31835}\n",
            "embedding has been saved to D:/OneDrive - MSFT/CodeSpace/BookRecSystem/temp/\n",
            "Finish: 2023-03-10 10:07:33\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "main(ProjectFolderDir = 'D:/OneDrive - MSFT/CodeSpace/BookRecSystem/',  # 之前定义的项目路径\n",
        "      neg_ratio= 3,  # 负采样倍率\n",
        "      min_item= 5,  # 最短序列要求\n",
        "      seq_max_len= 10,  # 截断序列长度\n",
        "      load= False , # 是否从已有数据读取\n",
        "      batch_size= 2048 , # batch大小\n",
        "      user_params= [512, 512, 256, 128, 64] , # 读者塔MLP参数\n",
        "      item_params= [1024, 512, 256, 128, 64] , # 图书塔MLP参数，要确保最后的维度一致\n",
        "      temperature= 0.02 , # 温度系数\n",
        "      learning_rate= 0.01 , # 学习率\n",
        "      weight_decay= 1e-4 , # 正则化系数\n",
        "      optimizer_fn= torch.optim.Adam ,  # 优化器\n",
        "      epoch= 1 , # 训练epoch\n",
        "      topk= 100 #推荐topk个商品 \n",
        "    )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "50Wpeh4WHOAw"
      },
      "source": [
        "运行结束后，在项目路径{ProjectFolderDir}下会产生文件\n",
        "\n",
        "{ProjectFolderDir}/data/processed/ZJULibrary2013_2019.csv # 合并整理后的数据集\n",
        "\n",
        "{ProjectFolderDir}/data/processed/data_process.npy # 训练集，验证集，测试集  *\n",
        "\n",
        "{ProjectFolderDir}/data/processed/raw_id_maps.npy # 原始的id字典    *\n",
        "\n",
        "{ProjectFolderDir}/log/{Start time}.txt # 以开始训练时间命名的日志文件\n",
        "\n",
        "{ProjectFolderDir}/temp/item.ann.index # 保存的用于召回的索引文件  *\n",
        "\n",
        "{ProjectFolderDir}/temp/item_embeddding.pth # 图书的embedding向量  *\n",
        "\n",
        "{ProjectFolderDir}/temp/user_embedding.pth # 读者的embedding向量  *\n",
        "\n",
        "{ProjectFolderDir}/temp/model.pth # 训练的模型参数\n",
        "\n",
        "其中注释后标*的是召回需要的文件（需要上传至服务器）"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "可以在终端中运行\n",
        "\n",
        "python ./scripts/RecItem.py '997e765063b98413f5b079c026468f8'\n",
        "\n",
        "测试推荐"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "torchrec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
