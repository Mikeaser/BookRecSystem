{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F6HoE9Yjdnl"
      },
      "source": [
        "# 图书推荐教程\n",
        "这个笔记本展示了如何对原始数据集进行预处理、特征提取、模型训练、评估等，最终将数据传送至远端服务器上进行推荐。笔记本中可能需要修改的是原始数据的存放路径，即第4个单元格中的DataDir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive    # 先挂载存放有原始数据的云端硬盘\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IphmX5ZxmCxk",
        "outputId": "ecc71c2b-b7ed-43d9-e873-a98ebb800c82"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Mikeaser/BookRecSystem.git  # 这个仓库是本次参赛的项目\n",
        "!pip install annoy # colab中只要安装一个包"
      ],
      "metadata": {
        "id": "YLtPaF3ajnHM",
        "outputId": "d0d4749e-bb54-4a15-bb0e-10c7e208a7cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'BookRecSystem' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: annoy in /usr/local/lib/python3.9/dist-packages (1.17.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U_YPAK5Ujdnp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ProjectFolderDir = '/content/BookRecSystem/'   # 项目文件夹的路径是相对于本笔记本路径而言的，当然也可以使用绝对路径\n",
        "DataDir = '/content/drive/MyDrive/DataSpace/' # 原始数据路径，根据实际情况修改"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rdsSxmcjdnq"
      },
      "source": [
        "初步分析阶段先将字段以字符串形式录入，便于后期统一格式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TLh-XcUJjdnr"
      },
      "outputs": [],
      "source": [
        "BigData = pd.read_csv(DataDir + \"浙江大学-图书外借数据-2013~2018.csv\", encoding='utf8', dtype=str)      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wU1YolFejdns"
      },
      "outputs": [],
      "source": [
        "SmallData = pd.read_csv(DataDir + \"浙江大学-图书外借数据-2019.csv\", encoding='utf8', dtype=str)         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpgm-qUQjdnt"
      },
      "source": [
        "下面是构建模型所需要的数据列"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xJzZpvmLjdnt"
      },
      "outputs": [],
      "source": [
        "user_columns = ['PATRON_ID', 'STUDENT_GRADE', 'PATRON_DEPT', 'PATRON_TYPE']\n",
        "# 用户侧特征       用户id          年级            学生学院       学生类型\n",
        "item_columns = ['ITEM_ID', 'SUBLIBRARY', 'ITEM_CALLNO', 'PUBLISH_YEAR', 'AUTHOR', 'TITLE', 'PRESS']\n",
        "# 物品侧特征       记录号      馆藏地         图书索书号        出版年          作者       题目    出版社\n",
        "time = 'LOAN_DATE'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY1n867jjdnu"
      },
      "source": [
        "将两份数据集合并"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_EfMIkpDjdnu"
      },
      "outputs": [],
      "source": [
        "UsedColumns = user_columns + item_columns + [time]\n",
        "UsedData = pd.concat([BigData[UsedColumns], SmallData[UsedColumns]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHEduvnwjdnv"
      },
      "source": [
        "本项目将借阅记录中的空值字段采用相同值’na'进行填充，特征处理时将其作为空特征。对于图书类别，将其索书号按/分割后得到图书大类CALLNO1与小类CALLNO2，将借阅日期转为整形，便于之后比较大小。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "AtPc6Mv2jdnv"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_Bletter(str0):   # 取出大写字母\n",
        "    b = re.sub(u\"([^\\u0041-\\u007a])\", \"\", str0)\n",
        "    return b\n",
        "\n",
        "UsedData = UsedData.fillna(value='na')\n",
        "UsedData['CALLNO1'] = UsedData['ITEM_CALLNO'].str.split('/', expand=True)[0].map(lambda x: get_Bletter(str(x)))\n",
        "UsedData['CALLNO2'] = UsedData['ITEM_CALLNO'].str.split('/', expand=True)[1].map(lambda x: get_Bletter(str(x)))\n",
        "UsedData[time]=UsedData[time].astype(int)\n",
        "UsedData = UsedData.drop(columns='ITEM_CALLNO')  # 删掉不再需要的列"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXXIdeYPjdnv"
      },
      "source": [
        "此时可以看到UsedData中的空值消失，并且多出了两个类别列"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yGtRpGvyjdnw",
        "outputId": "ba730091-a207-415f-d749-c76eb7f1b4b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2260649 entries, 0 to 192700\n",
            "Data columns (total 13 columns):\n",
            " #   Column         Dtype \n",
            "---  ------         ----- \n",
            " 0   PATRON_ID      object\n",
            " 1   STUDENT_GRADE  object\n",
            " 2   PATRON_DEPT    object\n",
            " 3   PATRON_TYPE    object\n",
            " 4   ITEM_ID        object\n",
            " 5   SUBLIBRARY     object\n",
            " 6   PUBLISH_YEAR   object\n",
            " 7   AUTHOR         object\n",
            " 8   TITLE          object\n",
            " 9   PRESS          object\n",
            " 10  LOAN_DATE      int64 \n",
            " 11  CALLNO1        object\n",
            " 12  CALLNO2        object\n",
            "dtypes: int64(1), object(12)\n",
            "memory usage: 241.5+ MB\n"
          ]
        }
      ],
      "source": [
        "UsedData.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMoaCMmyjdnw"
      },
      "source": [
        "将数据存入./data/processed中，作为后续分析数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "c-GURml7jdnw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "isExists=os.path.exists(ProjectFolderDir+\"data/processed/\")\n",
        "if not isExists:\n",
        "    os.makedirs(ProjectFolderDir+\"data/processed/\") \n",
        "\n",
        "UsedData.to_csv(ProjectFolderDir+\"data/processed/ZJULibrary2013_2019.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del BigData # 将之前的大数据变量清空，空出一部分内存\n",
        "del SmallData\n",
        "del UsedData"
      ],
      "metadata": {
        "id": "FnWxKoEkRPXZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "调用代码库中的主函数进行模型训练、评估等操作"
      ],
      "metadata": {
        "id": "y4GK7PA-4JvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append(ProjectFolderDir)\n",
        "\n",
        "from scripts.MainFile import main\n",
        "from utils.data import datapretreat, MatchDataGenerator\n",
        "from utils.features import SequenceFeature, SparseFeature\n",
        "from model.DSSM import DSSM\n",
        "import torch\n",
        "from utils.train import MatchTrainer\n",
        "import numpy as np\n",
        "import random\n",
        "from utils.recall import topn_evaluate\n",
        "\n",
        "# 固定随机数种子\n",
        "seed = 2023\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# 创建缓存目录\n",
        "\n",
        "isExist=os.path.exists(ProjectFolderDir+\"temp/\")\n",
        "if not isExist:\n",
        "    os.makedirs(ProjectFolderDir+\"temp/\")\n"
      ],
      "metadata": {
        "id": "RqzHKeH54If7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "调用主函数即可，运行的日志文件保存在ProjectFolderDir/log目录下"
      ],
      "metadata": {
        "id": "7yq7jM8rG62i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main(ProjectFolderDir,  # 之前定义的项目路径\n",
        "      neg_ratio= 3,  # 负采样倍率\n",
        "      min_item= 5,  # 最短序列要求\n",
        "      seq_max_len= 10,  # 截断序列长度\n",
        "      load= False , # 是否从已有数据读取\n",
        "      batch_size= 2048 , # batch大小\n",
        "      user_params= [512, 512, 256, 128, 64] , # 读者塔MLP参数\n",
        "      item_params= [1024, 512, 256, 128, 64] , # 图书塔MLP参数，要确保最后的维度一致\n",
        "      temperature= 0.02 , # 温度系数\n",
        "      learning_rate= 0.01 , # 学习率\n",
        "      weight_decay= 1e-4 , # 正则化系数\n",
        "      optimizer_fn= torch.optim.Adam ,  # 优化器\n",
        "      epoch= 10 , # 训练epoch\n",
        "      topk= 100 #推荐topk个商品 \n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "moinQ8105-oQ",
        "outputId": "305bd416-826e-4de4-e2ea-ff93fd595f82"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start: 2023-03-09 07:18:01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading data:: 100%|██████████| 8/8 [00:00<00:00, 54471.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "standard data has been generated\n",
            "epoch: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train:  16%|█▌        | 641/4067 [01:33<08:19,  6.85it/s, loss=0.513]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f8e9dbdc5005>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m main(ProjectFolderDir,  # 之前定义的项目路径\n\u001b[0m\u001b[1;32m      2\u001b[0m       \u001b[0mneg_ratio\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 负采样倍率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m       \u001b[0mmin_item\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 最短序列要求\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m       \u001b[0mseq_max_len\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# 截断序列长度\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mload\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;31m# 是否从已有数据读取\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BookRecSystem/scripts/MainFile.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m(ProjectFolderDir, neg_ratio, min_item, seq_max_len, load, batch_size, user_params, item_params, temperature, learning_rate, weight_decay, optimizer_fn, epoch, topk)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMatchTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0meva_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meva_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0meva_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meva_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meva_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tp'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0meva_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fn'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BookRecSystem/utils/train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_dataloader, val_dataloader, test_dataloader)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch_i\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0meva_test_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'calculate confusion matrix on test data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nconfusion_matrix on test data:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meva_test_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/BookRecSystem/utils/train.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, train_data_loader, val_data_loader, log_interval)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mtk0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_postfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlog_interval\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 输出平均值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "运行结束后，会产生文件\n",
        "\n",
        "{ProjectFolderDir}/data/processed/ZJULibrary2013_2019.csv # 合并整理后的数据集\n",
        "\n",
        "{ProjectFolderDir}/data/processed/data_process.npy # 训练集，验证集，测试集\n",
        "\n",
        "{ProjectFolderDir}/data/processed/raw_id_maps.npy # 原始的id字典  \n",
        "\n",
        "{ProjectFolderDir}/log/{Start time}.txt # 以开始训练时间命名的日志文件\n",
        "\n",
        "{ProjectFolderDir}/temp/item.ann.index # 保存的用于召回的索引文件\n",
        "\n",
        "{ProjectFolderDir}/temp/item_embeddding.pth # 图书的embedding向量\n",
        "\n",
        "{ProjectFolderDir}/temp/user_embedding.pth # 读者的embedding向量\n",
        "\n",
        "{ProjectFolderDir}/temp/model.pth # 训练的模型参数"
      ],
      "metadata": {
        "id": "50Wpeh4WHOAw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_EZzqADxI8l_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torchrec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}