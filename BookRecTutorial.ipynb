{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-F6HoE9Yjdnl"
      },
      "source": [
        "# 图书推荐教程\n",
        "### 数据悦读大赛作品\n",
        "这个笔记本展示了如何对原始数据集进行预处理、特征提取、模型训练、评估等，最终将生成的数据传送至远端服务器上进行推荐。笔记本中可能需要修改的是原始数据的存放路径，即文件中的DataDir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U_YPAK5Ujdnp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "ProjectFolderDir = './'   # 项目文件夹的路径是相对于本笔记本路径而言的，当然也可以使用绝对路径\n",
        "DataDir = './data/raw/' # 原始数据路径，根据实际情况修改"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rdsSxmcjdnq"
      },
      "source": [
        "初步分析阶段先将字段以字符串形式录入，便于后期统一格式"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TLh-XcUJjdnr"
      },
      "outputs": [],
      "source": [
        "BigData = pd.read_csv(DataDir + \"浙江大学-图书外借数据-2013~2018.csv\", encoding='utf8', dtype=str)       \n",
        "# 注意~是英文输入，读取不到可以重命名一下"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wU1YolFejdns"
      },
      "outputs": [],
      "source": [
        "SmallData = pd.read_csv(DataDir + \"浙江大学-图书外借数据-2019.csv\", encoding='utf8', dtype=str)         "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpgm-qUQjdnt"
      },
      "source": [
        "下面是构建模型所需要的数据列"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xJzZpvmLjdnt"
      },
      "outputs": [],
      "source": [
        "user_columns = ['PATRON_ID', 'STUDENT_GRADE', 'PATRON_DEPT', 'PATRON_TYPE']\n",
        "# 用户侧特征       用户id          年级            学生学院       学生类型\n",
        "item_columns = ['ITEM_ID', 'SUBLIBRARY', 'ITEM_CALLNO', 'PUBLISH_YEAR', 'AUTHOR', 'TITLE', 'PRESS']\n",
        "# 物品侧特征       记录号      馆藏地         图书索书号        出版年          作者       题目    出版社\n",
        "time = 'LOAN_DATE'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY1n867jjdnu"
      },
      "source": [
        "将两份数据集合并"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_EfMIkpDjdnu"
      },
      "outputs": [],
      "source": [
        "UsedColumns = user_columns + item_columns + [time]\n",
        "UsedData = pd.concat([BigData[UsedColumns], SmallData[UsedColumns]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHEduvnwjdnv"
      },
      "source": [
        "本项目将借阅记录中的空值字段采用相同值’na'进行填充，特征处理时将其作为空特征。对于图书类别，将其索书号按/分割后得到图书大类CALLNO1与小类CALLNO2，将借阅日期转为整形，便于之后比较大小。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "AtPc6Mv2jdnv"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def get_Bletter(str0):   # 取出大写字母\n",
        "    b = re.sub(u\"([^\\u0041-\\u007a])\", \"\", str0)\n",
        "    return b\n",
        "\n",
        "UsedData = UsedData.fillna(value='na')\n",
        "UsedData['CALLNO1'] = UsedData['ITEM_CALLNO'].str.split('/', expand=True)[0].map(lambda x: get_Bletter(str(x)))\n",
        "UsedData['CALLNO2'] = UsedData['ITEM_CALLNO'].str.split('/', expand=True)[1].map(lambda x: get_Bletter(str(x)))\n",
        "UsedData[time]=UsedData[time].astype(int)\n",
        "UsedData = UsedData.drop(columns='ITEM_CALLNO')  # 删掉不再需要的列"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXXIdeYPjdnv"
      },
      "source": [
        "此时可以看到UsedData中的空值消失，并且多出了两个类别列"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGtRpGvyjdnw",
        "outputId": "ba730091-a207-415f-d749-c76eb7f1b4b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 2260649 entries, 0 to 192700\n",
            "Data columns (total 13 columns):\n",
            " #   Column         Dtype \n",
            "---  ------         ----- \n",
            " 0   PATRON_ID      object\n",
            " 1   STUDENT_GRADE  object\n",
            " 2   PATRON_DEPT    object\n",
            " 3   PATRON_TYPE    object\n",
            " 4   ITEM_ID        object\n",
            " 5   SUBLIBRARY     object\n",
            " 6   PUBLISH_YEAR   object\n",
            " 7   AUTHOR         object\n",
            " 8   TITLE          object\n",
            " 9   PRESS          object\n",
            " 10  LOAN_DATE      int64 \n",
            " 11  CALLNO1        object\n",
            " 12  CALLNO2        object\n",
            "dtypes: int64(1), object(12)\n",
            "memory usage: 241.5+ MB\n"
          ]
        }
      ],
      "source": [
        "UsedData.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMoaCMmyjdnw"
      },
      "source": [
        "将数据存入./data/processed中，作为后续分析数据"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c-GURml7jdnw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "\n",
        "if not os.path.exists(ProjectFolderDir+\"data/processed/\"):\n",
        "    os.makedirs(ProjectFolderDir+\"data/processed/\") \n",
        "\n",
        "UsedData.to_csv(ProjectFolderDir+\"data/processed/ZJULibrary2013_2019.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FnWxKoEkRPXZ"
      },
      "outputs": [],
      "source": [
        "del BigData # 将之前的大数据变量清空，空出一部分内存\n",
        "del SmallData\n",
        "del UsedData"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "y4GK7PA-4JvE"
      },
      "source": [
        "#### 若已将两个数据集合并可以直接从此处开始\n",
        "调用代码库中的主函数进行模型训练、评估等操作"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "RqzHKeH54If7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/len/miniconda3/envs/torchrec/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "sys.path.append(ProjectFolderDir)\n",
        "\n",
        "from scripts.MainFile import main\n",
        "\n",
        "# 创建缓存目录\n",
        "\n",
        "if not os.path.exists(ProjectFolderDir+\"temp/\"):\n",
        "    os.makedirs(ProjectFolderDir+\"temp/\")\n",
        "if not os.path.exists(ProjectFolderDir+\"log/\"):\n",
        "    os.makedirs(ProjectFolderDir+\"log/\")\n",
        "\n",
        "# 这边可能会报warning:Please update jupyter and ipywidgets，不过对本项目无影响"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yq7jM8rG62i"
      },
      "source": [
        "调用主函数即可，运行的日志文件保存在ProjectFolderDir/log目录下"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "id": "moinQ8105-oQ",
        "outputId": "305bd416-826e-4de4-e2ea-ff93fd595f82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start: 2023-03-12 10:48:05\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "generate train set, validation set and test set:: 100%|██████████| 118358/118358 [00:15<00:00, 7407.61it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_train: 6246232, n_val: 1561559, n_test: 867533\n",
            "40557 cold start user droped \n",
            "train set, validation set and test set have saved in data/processed/data_process.npy\n",
            "standard data has been generated\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m main(ProjectFolderDir,  \u001b[39m# 之前定义的项目路径\u001b[39;49;00m\n\u001b[1;32m      2\u001b[0m       neg_ratio\u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m,  \u001b[39m# 负采样倍率\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m       min_item\u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m,  \u001b[39m# 最短序列要求\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m       seq_max_len\u001b[39m=\u001b[39;49m \u001b[39m20\u001b[39;49m,  \u001b[39m# 截断序列长度\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m       load\u001b[39m=\u001b[39;49m \u001b[39mFalse\u001b[39;49;00m , \u001b[39m# 是否从已有数据读取\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m       batch_size\u001b[39m=\u001b[39;49m \u001b[39m1024\u001b[39;49m , \u001b[39m# batch大小\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m       user_params\u001b[39m=\u001b[39;49m [\u001b[39m512\u001b[39;49m, \u001b[39m512\u001b[39;49m, \u001b[39m256\u001b[39;49m, \u001b[39m128\u001b[39;49m, \u001b[39m64\u001b[39;49m] , \u001b[39m# 读者塔MLP参数\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m       item_params\u001b[39m=\u001b[39;49m [\u001b[39m1024\u001b[39;49m, \u001b[39m512\u001b[39;49m, \u001b[39m256\u001b[39;49m, \u001b[39m128\u001b[39;49m, \u001b[39m64\u001b[39;49m] , \u001b[39m# 图书塔MLP参数，要确保最后的维度一致\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m       temperature\u001b[39m=\u001b[39;49m \u001b[39m0.02\u001b[39;49m , \u001b[39m# 温度系数\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m       learning_rate\u001b[39m=\u001b[39;49m \u001b[39m1e-4\u001b[39;49m , \u001b[39m# 学习率\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m       weight_decay\u001b[39m=\u001b[39;49m \u001b[39m1e-4\u001b[39;49m , \u001b[39m# 正则化系数\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m       optimizer_fn\u001b[39m=\u001b[39;49m torch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam ,  \u001b[39m# 优化器\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m       epoch\u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m , \u001b[39m# 训练epoch\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m       topk\u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m \u001b[39m#推荐topk个商品 \u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m     )  \u001b[39m# 大约需要1小时，Hit Rate 25%  最后的评估可能会耗时较久\u001b[39;00m\n",
            "File \u001b[0;32m~/CodeSpace/BookRecSystem/scripts/MainFile.py:57\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(ProjectFolderDir, neg_ratio, min_item, seq_max_len, load, batch_size, user_params, item_params, temperature, learning_rate, weight_decay, optimizer_fn, epoch, topk)\u001b[0m\n\u001b[1;32m     55\u001b[0m model \u001b[39m=\u001b[39m DSSM(user_features, item_features, user_params, item_params, temperature\u001b[39m=\u001b[39mtemperature)\n\u001b[1;32m     56\u001b[0m optimizer \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m: learning_rate, \u001b[39m\"\u001b[39m\u001b[39mweight_decay\u001b[39m\u001b[39m\"\u001b[39m: weight_decay}\n\u001b[0;32m---> 57\u001b[0m trainer \u001b[39m=\u001b[39m MatchTrainer(model, optimizer_fn\u001b[39m=\u001b[39;49moptimizer_fn, optimizer_params\u001b[39m=\u001b[39;49moptimizer, n_epoch\u001b[39m=\u001b[39;49mepoch, device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m'\u001b[39;49m, model_path\u001b[39m=\u001b[39;49mmodel_dir)\n\u001b[1;32m     59\u001b[0m eva_test \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39mfit(train_dl, val_dl, test_dl)\n\u001b[1;32m     60\u001b[0m auc \u001b[39m=\u001b[39m eva_test[\u001b[39m'\u001b[39m\u001b[39mtp\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m+\u001b[39meva_test[\u001b[39m'\u001b[39m\u001b[39mtn\u001b[39m\u001b[39m'\u001b[39m]\n",
            "File \u001b[0;32m~/CodeSpace/BookRecSystem/utils/train.py:12\u001b[0m, in \u001b[0;36mMatchTrainer.__init__\u001b[0;34m(self, model, optimizer_fn, optimizer_params, n_epoch, device, model_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model  \u001b[39m# for uniform weights save method in one gpu or multi gp\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(device)\n\u001b[0;32m---> 12\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mto(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     13\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mBCELoss()  \u001b[39m# default loss binary cross_entropy\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer \u001b[39m=\u001b[39m optimizer_fn(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mparameters(), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptimizer_params)  \u001b[39m# default optimizer\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/torchrec/lib/python3.10/site-packages/torch/nn/modules/module.py:989\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    985\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m    987\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 989\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
            "File \u001b[0;32m~/miniconda3/envs/torchrec/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/torchrec/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/torchrec/lib/python3.10/site-packages/torch/nn/modules/module.py:641\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    640\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 641\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    643\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    644\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    645\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    646\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    652\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
            "File \u001b[0;32m~/miniconda3/envs/torchrec/lib/python3.10/site-packages/torch/nn/modules/module.py:664\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    663\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 664\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    665\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    666\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
            "File \u001b[0;32m~/miniconda3/envs/torchrec/lib/python3.10/site-packages/torch/nn/modules/module.py:987\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    986\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 987\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
            "File \u001b[0;32m~/miniconda3/envs/torchrec/lib/python3.10/site-packages/torch/cuda/__init__.py:229\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39menviron:\n\u001b[1;32m    228\u001b[0m     os\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mCUDA_MODULE_LOADING\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mLAZY\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 229\u001b[0m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_cuda_init()\n\u001b[1;32m    230\u001b[0m \u001b[39m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[39m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    233\u001b[0m _tls\u001b[39m.\u001b[39mis_initializing \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW"
          ]
        }
      ],
      "source": [
        "main(ProjectFolderDir,  # 之前定义的项目路径\n",
        "      neg_ratio= 3,  # 负采样倍率\n",
        "      min_item= 5,  # 最短序列要求\n",
        "      seq_max_len= 20,  # 截断序列长度\n",
        "      load= False , # 是否从已有数据读取\n",
        "      batch_size= 1024 , # batch大小\n",
        "      user_params= [512, 512, 256, 128, 64] , # 读者塔MLP参数\n",
        "      item_params= [1024, 512, 256, 128, 64] , # 图书塔MLP参数，要确保最后的维度一致\n",
        "      temperature= 0.02 , # 温度系数\n",
        "      learning_rate= 1e-4 , # 学习率\n",
        "      weight_decay= 1e-4 , # 正则化系数\n",
        "      optimizer_fn= torch.optim.Adam ,  # 优化器\n",
        "      epoch= 5 , # 训练epoch\n",
        "      topk= 100 #推荐topk个商品 \n",
        "    )  # 大约需要1小时，Hit Rate 25%  最后的评估可能会耗时较久"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "50Wpeh4WHOAw"
      },
      "source": [
        "运行结束后，在项目路径{ProjectFolderDir}下会产生文件\n",
        "\n",
        "{ProjectFolderDir}/data/processed/ZJULibrary2013_2019.csv # 合并整理后的数据集\n",
        "\n",
        "{ProjectFolderDir}/data/processed/data_process.npy # 训练集，验证集，测试集  \n",
        "\n",
        "{ProjectFolderDir}/data/processed/item_user.npy # 用于召回时匹配embedding  *\n",
        "\n",
        "{ProjectFolderDir}/data/processed/raw_id_maps.npy # 原始的id字典    *\n",
        "\n",
        "{ProjectFolderDir}/log/{Start time}.txt # 以开始训练时间命名的日志文件\n",
        "\n",
        "{ProjectFolderDir}/temp/item.ann.index # 保存的用于召回的索引文件  *\n",
        "\n",
        "{ProjectFolderDir}/temp/item_embeddding.pth # 图书的embedding向量  *\n",
        "\n",
        "{ProjectFolderDir}/temp/user_embedding.pth # 读者的embedding向量  *\n",
        "\n",
        "{ProjectFolderDir}/temp/model.pth # 训练的模型参数\n",
        "\n",
        "其中注释后标*的是召回需要的文件（需要上传至服务器）"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "可以在终端中运行\n",
        "\n",
        "python ./scripts/RecItem.py '997e765063b98413f5b079c026468f8'\n",
        "\n",
        "测试推荐"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "torchrec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
